{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e3c2c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import warnings\n",
    "from typing import Tuple\n",
    "\n",
    "lucky_7 = 7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "613afffc",
   "metadata": {},
   "source": [
    "#### 1. `ahi_o0h3`\n",
    "\n",
    "* Counts **obstructive apneas** with **no oxygen desaturation threshold**, with or without arousal.\n",
    "* Counts **hypopneas** that have both:\n",
    "\n",
    "  * \\> 30% flow reduction for mare than $n$ $seconds$ (say $10s$)\n",
    "  * **AND** ≥3% oxygen desaturation\n",
    "  * With or without arousal.\n",
    "* The formula:\n",
    "\n",
    "  $\\text{AHI} = \\frac{\\text{(n obstructive apneas) + (n hypopneas meeting criteria)}}{\\text{hours of sleep}}$\n",
    "\n",
    "#### 2. `ahi_o0h3a`\n",
    "\n",
    "* Counts **obstructive apneas** same as above.\n",
    "* Counts **hypopneas** that have:\n",
    "\n",
    "  * \\> 30% flow reduction for mare than $n$ $seconds$ (say $10s$)\n",
    "  * **AND** either:\n",
    "\n",
    "    * ≥3% oxygen desaturation **OR**\n",
    "    * Presence of arousal\n",
    "* So this is a bit broader in the hypopnea count because it includes events with desaturation **or** arousal (not necessarily both).\n",
    "\n",
    "`≥3% oxygen desaturation`: this means the blood oxygen saturation (SpO₂) level drops by 3% or more from the baseline during a breathing event (like hypopnea or apnea).\n",
    "\n",
    "`> 30% flow reduction`: It refers to a partial blockage of the airway, leading to a reduction in airflow (but not a complete stop like in apnea). Specifically: the person’s breathing is reduced by at least 30% of normal baseline airflow. This is measured using nasal pressure sensors or thermal airflow sensors in polysomnography (PSG).\n",
    "\n",
    "`Arousal`: An arousal is a brief awakening or change in brain activity during sleep, detected by EEG.\n",
    "\n",
    "#### Key difference:\n",
    "\n",
    "* `ahi_o0h3`: Hypopneas require **both ≥3% desaturation AND with/without arousal**.\n",
    "* `ahi_o0h3a`: Hypopneas require **≥3% desaturation OR arousal** (more inclusive).\n",
    "\n",
    "#### What does this mean for your model?\n",
    "\n",
    "* Since you’re working with only **SpO₂ (oxygen saturation) signals**, you can detect events related to **desaturation** but **not arousals** (which require EEG).\n",
    "* So **`ahi_o0h3` aligns better** with your data, since it strictly requires ≥3% desaturation in hypopneas.\n",
    "* Using **`ahi_o0h3a` might overestimate hypopneas** in your dataset because it counts events with arousal but no desaturation, which you can’t detect with SpO₂ alone.\n",
    "\n",
    "#### Summary for your use case:\n",
    "\n",
    "| AHI Variable | Includes hypopneas with desaturation only? | Includes hypopneas with arousal only? | Suitable for SpO₂-only models? |\n",
    "| ------------ | ------------------------------------------ | ------------------------------------- | ------------------------------ |\n",
    "|**`ahi_o0h3`**| **Yes**                                    | **No**                                | **Yes**                        |\n",
    "| `ahi_o0h3a`  | Yes                                        | Yes                                   | No                             |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bb945e9",
   "metadata": {},
   "source": [
    "So, Based on the above logic let's choose `ahi_o0h3`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53f5b103",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class ConvBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size=3):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv1d(in_channels, out_channels, kernel_size, padding=1)\n",
    "        self.bn = nn.BatchNorm1d(out_channels)\n",
    "        self.act = nn.LeakyReLU()\n",
    "        self.pool = nn.MaxPool1d(kernel_size=2, stride=2)\n",
    "\n",
    "        # Optional 1x1 conv if channel sizes mismatch in skip\n",
    "        self.skip = nn.Conv1d(in_channels, out_channels, kernel_size=1) if in_channels != out_channels else nn.Identity()\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv(x)\n",
    "        out = self.bn(out)\n",
    "        out = self.act(out)\n",
    "        out = self.pool(out)\n",
    "\n",
    "        # Adjust skip path if necessary\n",
    "        skip = self.skip(x)\n",
    "        skip = self.pool(skip)  # apply same pooling\n",
    "        return out + skip\n",
    "\n",
    "\n",
    "class DilatedBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size=3, dilation=1):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv1d(in_channels, out_channels, kernel_size,\n",
    "                              padding=dilation, dilation=dilation)\n",
    "        self.act = nn.LeakyReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.act(self.conv(x))\n",
    "\n",
    "\n",
    "class OxiNetCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.window_size = 3600\n",
    "        self.num_windows = 7\n",
    "\n",
    "        # Local CNN blocks for each window: 1 -> 4 -> 8 channels\n",
    "        self.block1 = ConvBlock(1, 4)\n",
    "        self.block2 = ConvBlock(4, 8)\n",
    "        self.block3 = ConvBlock(8, 8)\n",
    "\n",
    "        # Dilated blocks for temporal features (example: 2 blocks)\n",
    "        self.dilated1 = DilatedBlock(8, 8, dilation=2)\n",
    "        self.dilated2 = DilatedBlock(8, 8, dilation=4)\n",
    "\n",
    "        # Flatten + Fully Connected Layer\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc = nn.Linear(8 * 98, 1)  # final AHI score\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (batch_size, 1, 25200)  ← 7 windows × 3600 samples\n",
    "\n",
    "        batch_size = x.size(0)\n",
    "        windows = x.unfold(dimension=2, size=self.window_size, step=self.window_size)  # shape: (B, 1, 7, 3600)\n",
    "        windows = windows.permute(0, 2, 1, 3)  # (B, 7, 1, 3600)\n",
    "\n",
    "        outputs = []\n",
    "        for i in range(self.num_windows):\n",
    "            w = windows[:, i]  # (B, 1, 3600)\n",
    "            out = self.block1(w)\n",
    "            out = self.block2(out)\n",
    "            out = self.block3(out)\n",
    "            outputs.append(out)\n",
    "\n",
    "        # Concatenate along time dimension\n",
    "        concat = torch.cat(outputs, dim=2)  # (B, 8, 7×225 = 1575)\n",
    "\n",
    "        # Dilated blocks\n",
    "        out = self.dilated1(concat)  # (B, 8, ~1575)\n",
    "        out = self.dilated2(out)     # (B, 8, ~1575)\n",
    "\n",
    "        # Downsample (if needed), then flatten\n",
    "        out = F.adaptive_avg_pool1d(out, 98)  # (B, 8, 98)\n",
    "        out = out.permute(0, 2, 1)            # (B, 98, 8)\n",
    "        out = self.flatten(out)              # (B, 98×8 = 784)\n",
    "\n",
    "        out = self.fc(out)                   # (B, 1) → AHI prediction\n",
    "\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7801a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# Define the path to your data folder\n",
    "base_path = \"data/shhs/polysomnography/edfs/shhs1\"\n",
    "\n",
    "# Prepare a list to collect each patient's signal\n",
    "signals = []\n",
    "ids = []\n",
    "# Loop through file IDs 200001 to 200016\n",
    "for pid in range(200001, 200289):\n",
    "    try:\n",
    "        file_path = os.path.join(base_path, f\"shhs1-{pid}_cleaned.parquet\")\n",
    "        \n",
    "        # Load the parquet file\n",
    "        df = pd.read_parquet(file_path)\n",
    "        \n",
    "        # FIX: Clean NaNs first!\n",
    "        df[\"SaO2\"] = df[\"SaO2\"].ffill().bfill()\n",
    "\n",
    "        # Now extract the signal (safe from NaNs)\n",
    "        spo2_signal = df[\"SaO2\"].values[:25200].astype(np.float32)\n",
    "\n",
    "        # Pad if needed\n",
    "        if len(spo2_signal) < 25200:\n",
    "            pad_len = 25200 - len(spo2_signal)\n",
    "            spo2_signal = np.pad(spo2_signal, (0, pad_len), mode='edge')\n",
    "\n",
    "        # Optional: Clip and normalize\n",
    "        spo2_signal = np.clip(spo2_signal, 0, 100)\n",
    "        spo2_signal = spo2_signal / 100.0\n",
    "\n",
    "        # Convert to torch tensor and add channel dim\n",
    "        tensor = torch.tensor(spo2_signal, dtype=torch.float32).unsqueeze(0)  # (1, 25200)\n",
    "        signals.append(tensor)\n",
    "        ids.append(pid)\n",
    "    except:\n",
    "        print(\"skipping...\")\n",
    "\n",
    "# Final stack\n",
    "batch_tensor = torch.stack(signals)  # (16, 1, 25200)\n",
    "\n",
    "# ✅ Final check\n",
    "print(\"Any NaNs in batch_tensor?\", torch.isnan(batch_tensor).any())  # Should be: tensor(False)\n",
    "print(batch_tensor.shape)  # torch.Size([16, 1, 25200])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "573d63f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "shhs1_dataset_df = pd.read_csv(\"shhs1-dataset-0.21.0.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e80cae43",
   "metadata": {},
   "outputs": [],
   "source": [
    "shhs1_dataset_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbb8eebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Suppose batch_tensor is your input: shape (16, 1, 25200)\n",
    "# And you have corresponding AHI labels:\n",
    "ahi_labels_np = shhs1_dataset_df[shhs1_dataset_df[\"nsrrid\"].isin(ids)][\"ahi_o0h3\"].values.astype(np.float32)\n",
    "ahi_labels = torch.tensor(ahi_labels_np).unsqueeze(1)\n",
    "# ahi_mean = ahi_labels.mean()\n",
    "# ahi_std = ahi_labels.std()\n",
    "# ahi_labels = (ahi_labels - ahi_mean) / ahi_std\n",
    "\n",
    "# Define model\n",
    "model = OxiNetCNN()\n",
    "\n",
    "# Loss function (regression)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# Optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "# Move to GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "batch_tensor = batch_tensor.to(device)\n",
    "ahi_labels = ahi_labels.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9d4c882",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop\n",
    "n_epochs = 5000\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    model.train()\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(batch_tensor)  # shape: (16, 1)\n",
    "    # outputs = outputs * ahi_std + ahi_mean\n",
    "    loss = criterion(outputs, ahi_labels)\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if (epoch + 1) % 10 == 0 or epoch == 0:\n",
    "        print(f\"Epoch {epoch+1}/{n_epochs}, Loss: {loss.item()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd14139f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ahi_pred = model(batch_tensor)\n",
    "\n",
    "# ahi_pred = ahi_pred * ahi_std + ahi_mean\n",
    "\n",
    "print(ahi_pred.shape)  # Expected: torch.Size([16, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1385257",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(torch.isnan(batch_tensor).any())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2013394",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame({\"pred\": ahi_pred.squeeze(1).tolist(), \"true\": ahi_labels.squeeze(1).tolist()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c0f4803",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(ahi_pred.squeeze(1).tolist(), ahi_labels.squeeze(1).tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "affca92b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "base_path = \"data/shhs/polysomnography/edfs/shhs1\"\n",
    "\n",
    "for pid in range(200001, 200265):\n",
    "    try:\n",
    "        file_path = os.path.join(base_path, f\"shhs1-{pid}_cleaned.parquet\")\n",
    "        # Load the parquet file\n",
    "        df = pd.read_parquet(file_path)\n",
    "        if (df.isna().sum() > 0).values[0]:\n",
    "            print(f\"nsrrid:{pid} null:{df.isna().sum()}\")\n",
    "    except:\n",
    "        # print(\"skipping...\")\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3e2b882",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = os.path.join(base_path, f\"shhs1-200018_cleaned.parquet\")\n",
    "# Load the parquet file\n",
    "df_200015 = pd.read_parquet(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69f5abc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03dfd28f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(50, 5))\n",
    "plt.plot(range(df_200015.shape[0]), df_200015)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "337ebe3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "df_200015[df_200015.isna().values.flatten()].to_csv(\"nan.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "523e3d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_200015.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f82994e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langsmith",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
